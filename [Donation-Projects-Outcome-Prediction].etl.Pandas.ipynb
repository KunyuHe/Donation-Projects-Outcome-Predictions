{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Predicting Donation Projects Outcome Based on DonorsChoose.org Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Extract, Transform, Load (ETL) Notebook", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### *Author: Kunyu He*\n#### *University of Chicago CAPP'20*", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Executive Summary", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this ETL notebook, I load the data, which comes separately in `.csv` format from [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage?S_PKG=AW&cm_mmc=Search_Google-_-Cloud_Cloud+Platform-_-WW_NA-_-+ibm++object++storage_Broad_&cm_mmca1=000016GC&cm_mmca2=10007090&cm_mmca7=9060146&cm_mmca8=aud-311016886972:kwd-346458796492&cm_mmca9=_k_CjwKCAiAyfvhBRBsEiwAe2t_i-XCqy6aVw7VL5rPgPbazlACBDB8tL5qFioP_k0oLEF8dxisH8cTlBoClHoQAvD_BwE_k_&cm_mmca10=317209285867&cm_mmca11=b&mkwid=_k_CjwKCAiAyfvhBRBsEiwAe2t_i-XCqy6aVw7VL5rPgPbazlACBDB8tL5qFioP_k0oLEF8dxisH8cTlBoClHoQAvD_BwE_k_|1445|530530&cvosrc=ppc.google.%2Bibm%20%2Bobject%20%2Bstorage&cvo_campaign=000016GC&cvo_crid=317209285867&Matchtype=b&gclid=CjwKCAiAyfvhBRBsEiwAe2t_i-XCqy6aVw7VL5rPgPbazlACBDB8tL5qFioP_k0oLEF8dxisH8cTlBoClHoQAvD_BwE), as Pandas DataFrames and performs data preprocessing with Python's [Pandas](https://pandas.pydata.org/) library. The data cleaning part includes the following:\n\n* Extracting relevant columns from the `outcomes` and `resources` data sets\n* Merging all separate dataframes on primary key `projectid`\n* Extracting the original training set based on dates the projects were posted *(only those posted before 01/01/2014)* and split it into new training and test set\n* Dropping irrelevant columns and columns with more than 10% values missing\n* Encoding some columns as binary dummies and converting some others to categoricals\n* Dropping rows that still contain NA values\n\nAfter preprocessing, the output dataframes *(`train` and `test`)* are stored in `.csv` format back to object storage as data assets named accordingly *(`train.csv` and `test.csv`)* for future use.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Extracting Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Data used for this project comes from Kaggle competition [KDD Cup 2014 - Predicting Excitement at DonorsChoose.org](https://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose/overview). Kaggle users who participate in the competition could get access to data in CSV format [here](https://www.kaggle.com/c/3926/download-all).", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "Basically there are five data sets, namely `projects`, `resources`, `essays`, `donations` and `outcomes`:\n\n* `projects` - contains information about each project. This is provided for both the training and test set.\n* `resources` - contains information about the resources requested for each project. This is provided for both the training and test set.\n* `essays` - contains project text posted by the teachers. This is provided for both the training and test set.\n* `donations` - contains information about the donations to each project. This is only provided for projects in the training set.\n* `outcomes` - contains information about the outcomes of projects in the training set.\n\n**Since `outcomes` is only provided for the training set and access to test set is blocked by Kaggle. Information on whether a project posted after 2014-01-01 got fully funded is not available. Hence we only use the original training set and split it into new training and test set.**\n\n**Notice that once we know the total price a project required, combined with total donations the project got, predicting `fully_funded` would be meaningless. So we won't use `donations` data set to train or test our model.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Loading Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pandas as pd\n\nfrom sklearn.model_selection import train_test_split"
        }, 
        {
            "source": "Use the chunks below to list the data assets in my IBM Cloud Object Storage linked to this project. As it includes my credentials, the code is hidden from unauthorized viewers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "Load data into the environment.\n\nNote that information in other columns from the `outcomes` data set can be used to infer whether a project got fully funded with certainty, I'm only using outcome of the donation projects *(`fully_funded`)* and whether the project has a comment thread with greater than average unique comments *(`great_chat`)* from the `outcomes` data set.\n\nAlso note that I'm only using the number of items required and statistics of `item_unit_price` as potential predictors from the `resources` data set. As I regard other columns as irrelevant.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Names of loaded dataframes:  ['essays', 'outcomes', 'projects', 'resources']\n"
                }
            ], 
            "source": "projects = pd.read_csv(project.get_file('Donation-Projects-Outcome-Prediction.data.projects.csv'))\noutcomes = pd.read_csv(project.get_file('Donation-Projects-Outcome-Prediction.data.outcomes.csv'),\n                       usecols=['projectid', 'fully_funded', 'great_chat'])\nresources = pd.read_csv(project.get_file('Donation-Projects-Outcome-Prediction.data.resources.csv'),\n                        usecols=['projectid', 'item_unit_price'])\nessays = pd.read_csv(project.get_file('Donation-Projects-Outcome-Prediction.data.essays.csv'))\n\nprint(\"Names of loaded dataframes: \", [instance for instance in dir() if isinstance(eval(instance),\n                                                                                    pd.core.frame.DataFrame)])"
        }, 
        {
            "source": "### Transforming Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "**We are only using the number of items required and statistics of `item_unit_price` as potential predictors from the `resources` data set.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "resources = resources.groupby('projectid')['item_unit_price'].agg(['count', 'min', 'median', 'max']).reset_index()\nresources.columns = ['projectid', 'number_of_items', 'min_price_items', 'median_price_items', 'max_price_items']"
        }, 
        {
            "source": "**Merge `projects`, `outcomes`, `essays` and `resources` data on `projectid`.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "merged = projects.merge(outcomes, how='outer', on='projectid').merge(essays, how='outer', on='projectid').merge( \\\n                        resources, how='outer', on='projectid')\nmerged.date_posted = pd.to_datetime(merged.date_posted)"
        }, 
        {
            "source": "**Extract the original training set from the merged data set according to dates the projects were posted. Split it into new training set and test set with a test proportion of 0.25.**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "There are 464494 observations in training set (75% of the observations), 154832 in test set and 46 features.\n"
                }
            ], 
            "source": "train, test = train_test_split(merged[merged.date_posted < \"2014-01-01\"], test_size=0.25, random_state=999)\nprint(\"There are {} observations in training set (75% of the observations), {} in test set and {} features.\".format( \\\n      train.shape[0], test.shape[0], train.shape[1]))"
        }, 
        {
            "source": "Define a function for data cleaning and perform the cleaning on both train and test set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def clean(df):\n    # drop features with 10% or more values missing\n    df.drop(df.columns[df.isnull().sum(axis=0) > df.projectid.nunique()*0.1], axis=1, inplace=True)\n    \n    # redundant information to drop\n    df.drop(['projectid', 'teacher_acctid_x', 'schoolid', 'school_ncesid', 'school_latitude',\n             'school_longitude', 'school_city', 'school_district', 'school_county', 'school_zip',\n             'teacher_acctid_y', 'fulfillment_labor_materials'], axis=1, inplace=True)\n    \n    # convert to binary dummy\n    binary = ['school_charter', 'school_magnet', 'school_year_round', 'school_nlns',\n              'school_kipp', 'school_charter_ready_promise', 'teacher_teach_for_america',\n              'teacher_ny_teaching_fellow', 'eligible_double_your_impact_match',\n              'eligible_almost_home_match', 'fully_funded', 'great_chat']\n    for col in binary:\n        df[col].replace(to_replace=[\"f\", \"t\"], value=[0, 1], inplace=True)\n        df[col] = df[col].astype(\"category\")\n\n    # convert to categorical\n    cat = ['school_state', 'teacher_prefix', 'primary_focus_subject', 'primary_focus_area',\n           'resource_type', 'poverty_level', 'grade_level']\n    for col in cat:\n        df[col] = df[col].astype(\"category\")\n\n    return df.dropna(axis=0, inplace=False)"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Now there are 458051 observations in the training set, 152697 in the test set and 31 features. Data is ready for analysis\n"
                }
            ], 
            "source": "train = clean(train)\ntest = clean(test)\n\nprint(\"Now there are {} observations in the training set, {} in the test set and {} features.\".format( \\\n      train.shape[0], test.shape[0], train.shape[1]))"
        }, 
        {
            "source": "### Data Outputs Storage", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Now save both training set and test set as `.csv` files and upload them back to my IBM Cloud Object Storage bucket.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "{'asset_id': 'f5450447-79fb-4b53-b646-5fbb9a220a8f',\n 'bucket_name': 'donationprojectsoutcomeprediction-donotdelete-pr-felyzh04iugf9l',\n 'file_name': 'Donation-Projects-Outcome-Prediction.data.train.csv',\n 'message': 'File Donation-Projects-Outcome-Prediction.data.train.csv has been written successfully to the associated OS'}"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "project.save_data(data=train.to_csv(index=True),\n                  file_name='Donation-Projects-Outcome-Prediction.data.train.csv', overwrite=True)"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 10, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "{'asset_id': '7a2d8b2c-65c5-4258-8605-b95653bd30c5',\n 'bucket_name': 'donationprojectsoutcomeprediction-donotdelete-pr-felyzh04iugf9l',\n 'file_name': 'Donation-Projects-Outcome-Prediction.data.test.csv',\n 'message': 'File Donation-Projects-Outcome-Prediction.data.test.csv has been written successfully to the associated OS'}"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "project.save_data(data=test.to_csv(index=True),\n                  file_name='Donation-Projects-Outcome-Prediction.data.test.csv', overwrite=True)"
        }, 
        {
            "source": "Check whether the output data files are successfully uploaded.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 11, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[{'asset_id': '7a2d8b2c-65c5-4258-8605-b95653bd30c5',\n  'name': 'Donation-Projects-Outcome-Prediction.data.test.csv'},\n {'asset_id': 'f5450447-79fb-4b53-b646-5fbb9a220a8f',\n  'name': 'Donation-Projects-Outcome-Prediction.data.train.csv'},\n {'asset_id': 'b6920713-693a-454e-855f-a24c95efd8ce',\n  'name': 'Donation-Projects-Outcome-Prediction.data.projects.csv'},\n {'asset_id': '9b1c8961-1564-41a7-8402-89fded8d7e21',\n  'name': 'Donation-Projects-Outcome-Prediction.data.outcomes.csv'},\n {'asset_id': '42bb6e53-4a3c-48f5-bcfb-5a7ab6b4461c',\n  'name': 'Donation-Projects-Outcome-Prediction.data.resources.csv'},\n {'asset_id': '260878e4-a8c3-4c74-8070-48813214e8b2',\n  'name': 'Donation-Projects-Outcome-Prediction.data.essays.csv'}]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "project.get_files()"
        }, 
        {
            "source": "Now that our data is stored properly, the ETL process for this project is done.\n\n**Cheers!**", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}